# All alert types are given one or more "tags", in a comma-separated list.  These tags are
# to be used by programs which consume the server's logs and perform actions based
# on the alerts and tags which appear in those logs.
# There are also three special tags - RED, AMBER and GREEN.  Alerts tagged with these
# values will appear in the browser UI provided by the server's built-in web server.

# The following alert types are used to collect information from log files:
# - alert_all:
# - alert_count:
# - alert_range:
# - alert_total:
# - alert_minimum:
# - alert_maximum:
# - alert_average:

# "alert_all:" consumes a log file and triggers an alert each time a line containing a particular
# string match is found:

file:         <log_file_name>
match:        <regular_expression>
alert_all:    tags=<tags>

# You can also add an optional "active:" directive which describes when this check will be active.
# The "active:" line is a comma-separated list of <days>;<hour/min_range> items.
# <days> are days of the week - numbered 1-7 where 1 = Sunday, 2 = Monday etc.
# <hour/min_range> is written as start hour/min - end hour/min in the format
# HH:MM-HH:MM.
# "active:" can be used with any alert type.

# Below is an example of "alert_all:" where lines containing "Type: <number>" are found.
# The consumer is only active from 09:00 - 17:30 Monday - Friday and 10:00 - 16:00 Saturday - Sunday.

file:        logfile.log
active:      23456;09:00-17:30,17;10:00-16:00
match:       Type: \d+
alert_all:   tags=RED

# The "alert_all:" line can also trigger a customised message, as follows:

alert_all:   tags=RED  message=Type identified

# In this case, the alert recorded (and sent to the UI if a RED, AMBER or GREEN tag is included
# in the tag list) will contain the customised message rather than the line in the
# log file which was captured.
# Note that "message=" has to be the last attribute on the "alert_all:" line.

# We may want to extract a particular item from a log file string match - for example a numerical value.
# This can be done using the "capture" directive which indicates which part of the log file line needs
# to be retained instead of specifying the "match" directive.

# The following example shows a numerical value being extracted from an incoming log file line:

file:        logfile.log
capture:     Type: (\d+)
alert_all:   tags=THE_VALUE

# ... which would output "109" if logfile.log contained the line "Type: 109".
# This feature can also be used, for example, to remove unwanted parts of log file lines - eg. time-stamps.
# The line:

Sun Jan 03 20:53:54 GMT 2016 [Thread-2]: Warning: Restart in progress

# Could be captured as simply "Warning: Restart in progress" by using:

capture:     Thread.\d+.: (.+)

# (Useful for de-duplicating multiple alerts with different time-stamps when they appear in the
# browser UI.)

# In any part of an alert (message, tags etc.), the string #hostname# will be replaced by the name
# of the host that the Client is running on.

# Where an alert is of the form:
# <string>: <numeric value>
# ... and one of the tags for the Schnauzer starts with "METRIC_", the Server will write the numeric value
# captured to a file in the Server's root folder called "metrics/YYYY-MM-DD/<metric_name>" - where
# <metric_name> is the part of the tag following "METRIC_".
# Eg:

file:        logfile.log
capture:     Type: (\d+)
alert_all:   tags=METRIC_A_VALUE

# ... will append a line to "metrics/YYYY-MM-DD/A_VALUE" each time "Type: <value>" is encountered in logfile.log.
# This allows metric history to be viewed via the browser.

# For:

file:        logfile.log
capture:     Type: (\d+)
alert_all:   tags=METRIC_A_#hostname#

# ... the metric will be written to "metrics/YYYY-MM-DD/A_<hostname>" where <hostname> is the name of the
# host where the Client is running.

# "alert_count:" triggers a periodic alert which indicates the number of times a particular
# regular expression has been matched in a log file over a set period of time.
# For example, the following:

file:          logfile.log
match:         Type: \d+
alert_count:   tags=RED   seconds=60

# ... triggers an alert every minute which contains the number of times the string "Type: <number>"
# appears in logfile.log.  The "RED" tag means that this alert will be displayed as a red
# (highest priority) alarm in the browser UI.

# If an "alert_count" tag starts with "METRIC_", then the Server will log the value contained in the alert
# to "metrics/YYYY-MM-DD/<metric_name>".

# It is also possible to perform very basic mathematical operations on values captured from log files
# using the "alert_total", "alert_minimum", "alert_maximum" and "alert_average" directives.
# This feature is useful for charting, for example, periodic min, max and average handling times for a web-service
# captured from an Apache HTTPD access log file.
# These all require a "capture" directive to be used and will output a value after a set period.
# Here are some examples:

file:          logfile.log
capture:       Type: (\d+)
alert_total:   tags=METRIC_TOTAL   seconds=60

file:          logfile.log
capture:       Type: (\d+)
alert_minimum: tags=METRIC_MINIMUM   seconds=60

file:          logfile.log
capture:       Type: (\d+)
alert_maximum: tags=METRIC_MAXIMUM   seconds=60

file:          logfile.log
capture:       Type: (\d+)
alert_average: tags=METRIC_AVERAGE   seconds=60

# Note that no alert is triggered for average, minimum or maximum if nothing has been captured
# from the log file during the specified interval.

# The "alert_total" and "alert_average" directives can also be used for threshold alerting
# by specifying a minimum or maximum value plus alert message, for example:

file:          logfile.log
capture:       Type: (\d+)
alert_total:   tags=ALERT_TOTAL   seconds=60   minimum=10   message=Total is below ten

file:          logfile.log
capture:       Type: (\d+)
alert_total:   tags=ALERT_TOTAL   seconds=60   maximum=10   message=Total is above ten

file:          logfile.log
capture:       Type: (\d+)
alert_total:   tags=ALERT_TOTAL   seconds=60   minimum=5   minimum=10   message=Total is outside of range 5-10

# Or:

file:          logfile.log
capture:       Type: (\d+)
alert_average: tags=ALERT_AVERAGE   seconds=60   minimum=10   message=Average is below ten

file:          logfile.log
capture:       Type: (\d+)
alert_average: tags=ALERT_AVERAGE   seconds=60   maximum=10   message=Average is above ten

file:          logfile.log
capture:       Type: (\d+)
alert_average: tags=ALERT_AVERAGE   seconds=60   minimum=5   minimum=10   message=Average is outside of range 5-10

# The above are extremely useful for raising alerts based on component throughput and average handling
# times exceeding design thresholds.

# "alert_range:" is used to trigger a periodic alert if the number of matches in a log file
# falls outside a set range during that time period.  For example, the following fires off an
# alert if there are less than 3 or more than 6 instances of the string "Type X" appearing
# in logfile.log within a minute:

file:         logfile.log
match:        Type X
alert_range:  tags=AMBER,X_RANGE  seconds=60  minimum=3  maximum=6

# "minimum=" and "maximum=" can be specified on their own, for example, the
# following could be used to raise an alert if the file logfile.log hasn't
# been updated at all over the last minute (useful for detecting if a program
# has entered a "hung" state) and we require this check to only be active
# between 07:00 and 22:00 on any day of the week:

file:         logfile.log
match:        .+
active:       1234567;07:00-22:00
alert_range:  tags=INACTIVE  seconds=60  minimum=1

# (Note that .+ matches one or more of any character - ie. any line.)

# This example triggers an alert if more than 20 lines containing
# "Exception" appear in logfile.log within a five minute period:

file:        logfile.log
match:       Exception
alert_range: tags=RED,EXCEPTION  seconds=300  maximum=20

# "alert_range:", just like "alert_all:", can be provided with a customised
# message to include in the alert instead of the match count.
# For example:

alert_range: tags=RED,EXCEPTION  seconds=300  maximum=20 message=Out of bounds

# The next set of alert types are used to examine disk usage and
# running processes.

# "alert_disk:" is used to check available space on a disk.
# The following raises an alert if utilised space on the
# root filesystem exceeds 80%:

file:        /
alert_disk:  tags=ROOT_FS,RED   maximum=80

# In addtion to the above, if you include:

file:        /
alert_disk:  tags=ROOT_FS,AMBER   maximum=70

# ... then an Amber alert (in the UI) will appear if root filesystem
# space exceeds 70%, and then a Red alert will appear if space
# exceeds 80%.

# To monitor for the presence (or non-presence) of processes, use
# the "alert_process:" directive.

# Firstly, we need to set the command used to fetch the process table.
# For example, on Linux we could set this as follows:

ps_command:   ps -fe

# On Windows, we would use:

ps_command:   tasklist.exe

# Then, we define pattern matches and "alert_process:" statements.
# Eg. to raise an alert if no Apache httpd process are running or
# if more than 20 are running:

match:          httpd
alert_process:  tags=AMBER,APACHE  minimum=1  maximum=20

# Note that we have to specify both "minimum" and "maximum"
# unlike with "alert_count:".

# If we would like an alert to be triggered if anything other
# than a set number of processes are running, then we specify "exactly"
# instead of "minimum" and "maximum".
# For example, if only one instance of "chart_load" should be running at
# any time:

match:         chart_load
alert_process  tags=CHARTING  exactly=1

# The client can run commands and raise alerts if any lines in the
# command output match a regular expression.  This is generally used for
# custom monitoring by running a script.
# The following runs "df -i ." every 150 seconds and captures any lines
# which contain a number, followed by one or more spaces, then another
# number, then another one or more spaces.  The "active:" directive means
# that the command will only be run from 17:00 - 19:00 on Saturday and Sunday.

match:             \d+\s+\d+\s+
active:            17;17:00-19:00
alert_cmd:         tags=CMD,GREEN  seconds=150   command=df -i .

# If an "alert_cmd" tag starts with "METRIC_", and the command output is of the form:
# <string>: <value>
# ... then the Server will log the value contained in the alert
# to "metrics/YYYY-MM-DD/<metric_name>".

# The alert_cmd directive can also be used with capture rather than match, for example:

capture: DISK2\s+\d+\s+(\d+)
alert_cmd: tags=CMD,GREEN seconds=150 command=df -i .

# The above will find lines that are of the form:
# DISK2 <number1> <number2>
# ... and return the value of <number2> only.

# The alert_cmd directive can also be provided with threshold values which apply when used in conjunction with the capture directive.  For example:

capture: DISK2\s+\d+\s+(\d+)
alert_cmd: tags=CMD,GREEN seconds=150 maximum=10 command=df -i .

# ... will raise a second alert (in addition to the alert containing the actual value of the metric), containing the text Exceeded Upper Bound if the value captured exceeds 10.  Likewise:

capture: DISK2\s+\d+\s+(\d+)
alert_cmd: tags=CMD,GREEN seconds=150 minimum=5 command=df -i .

# ... will raise a second alert, containing the text Below Lower Bound if the value captured is below 5.
# Both the maximum and minimum parameters can be used in the same alert_cmd declaration.

# Alternative tags can be specified for the threshold breach alert within alert_cmd as follows:

capture: DISK2\s+\d+\s+(\d+)
alert_cmd: tags=CMD,GREEN seconds=150 minimum=5 threshold_tags=RED command=df -i .

# In order to check whether a TCP server is ready to accept incoming connections
# (eg. a web server), use the "alert_tcp" directive.
#
# For example, the following line checks if port 80 at 127.0.0.1 is accepting
# connections every 60 seconds.

alert_tcp:         tags=WEB_SRV,RED  seconds=60  ip=127.0.0.1  port=80  timeout=2  message=Apache HTTPD is not running

# The "timeout" parameter specifies that the check
# will only wait two seconds before giving up.  The "message" parameter (must be
# at the end of the line) contains the message to log if the connection test fails.

# A "Multi" monitor can be set up which will trigger an alert if
# a Client detects a series of alerts containing tags in a watchlist
# within a set period of time.  Here's an example:

file:              test.log
match:             type_1
alert_all:         tags=TAG1,INFO

file:              test.log
match:             type_2
alert_all:         tags=TAG2,INFO

alert_multi:       tags=RED,DERIVED  seconds=60  collect=TAG1,TAG2  message=Both types found

# Here we've set up two file schnauzers which detect log lines containing "type_1" and "type_2".  Each
# schnauzer triggers an alert containing either TAG1 or TAG2.
# The "alert_multi" line uses it's "collect" attribute to specify that if other alerts containing
# the tags TAG1 and TAG2 have been raised in the last 60 seconds, then a RED,DERIVED alert with the
# message "Both types found" will be raised.
# Multi monitors can be used by Clients monitoring the Server event log in order to collect alerts
# raised by different Clients and trigger further alerts if these are seen (alert correlation).
# An example usage of Multi monitors would be to raise a high-priority alert if an entire group
# of servers aren't running a particular process.

# It's also possible to configure a Client to receive alert notifications as incoming
# REST web hooks.  To set this up, use the "alert_rest" directive:

alert_rest:        port=<tcp_port_number>

# For example:

alert_rest:        port=5656

# REST requests use a URL formed in this way:

# /alert/<TAGS>/<MESSAGE>

# For example, using curl:

# curl 'http://192.168.1.20:5656/alert/RED,MSGQ/Inbound_queue_server:%020Queue%20is%20full'

# Note '%20' used for spaces in the message text and that the alert hostname will be the name of the
# host on which the Client is running.
